10月20日
先生と簡単な面談を行いました。
後期に入ってから本日までに改善させたモデルの正答率のことや、LLMに外部ツールを使用させる方向性についても話しました。

すでにインストールしていたLMstudioというLLMモデルを動かせるアプリを介して外部ツール使用について簡単な実験に取り組みます。
そこまでの流れを説明します。
LMstudioはサーバの役割
エージェント実行はPythonファイル
APIリクエスト送信はインストールしたLangChainのChatOpenAIクラスが担当
推論とレスポンスはLMstudioのモデル
結果処理と回答生成はLangChainのエージェントが担当

このようになっています。

# 1. ライブラリのインストール（まだであれば）
# pip install langchain langchain-openai

AIにコードを書かせていろいろと試しましたが、うまくいかずlangchainのバージョンと生成されたコードが合わないためであったようです。
test2.pyに失敗したソースコードを集めてコメントアウトして置いています。
test.pyにはうまく動いたコードだけを置いています。
何がうまくいったかというと、LM studioでサーバを起動し、モデルLlamaにターミナル上で指示して計算させるというものです。


10月22日
前期のプロジェクトフォルダでうまくいったモデルに関して、構築するのに必要な学習用データセット生成スクリプトや訓練用ソースコードなど、まとめました。
